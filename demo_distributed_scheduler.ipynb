{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of a distributed scheduler\n",
    "\n",
    "Gotta import the stuff we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a cluster\n",
    "\n",
    "Start by creating a `LocalCluster` with some parameters. We can use the `print` method in `LocalCluster` to see some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=1, threads_per_worker=1)\n",
    "print(cluster)  # call print due to ipywidgets bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first address is the address to the scheduler, which is useful if we need to directly interact with the scheduler from other computers/nodes (usually, we don't).\n",
    "\n",
    "We can examine some information on both the scheduler and the workers that are associated with this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't talked about the \"Nanny\" process -- this is a small process that spawns, monitors and kills workers when their work is done. She's a fierce nanny, that one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dashboard\n",
    "\n",
    "The really, really cool thing about setting up clusters like this is that they come with a neat dashboard. We can access it using the handy method associated with the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main cool tabs are the Status and Graph tabs. **Note**: if for some reason your Graph tab is not showing your task graph, it may have to do with changing the settings of your cluster. Try restarting the kernel and reloading the dashboard, and it should work.\n",
    "\n",
    "## Create a client\n",
    "\n",
    "We've created the cluster, and the next step is to interface a client with the cluster. Once we do this, any subsequent calls of `dask.compute` will launch on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, when printed in a Jupyter cell, the client prints cool information about the scheduler, Dashboard and cluster.\n",
    "\n",
    "## Create task graph\n",
    "\n",
    "We need to create our task graph before we can launch it. Let's reuse our `myreduce` task graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    n = 2e7\n",
    "    while n>0:\n",
    "        n -= 1\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load 2_problem.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = myreduce(dask.delayed(add), range(12))\n",
    "z.visualize(rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the task graph onto the scheduler\n",
    "\n",
    "Since we've connected to a cluster through a client, dask knows to deploy this task graph on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the client and cluster\n",
    "\n",
    "Dask sometimes has issues shutting down the cluster's dashboard, so I would recommend using both the client and the cluster as context managers in real scripts. But since we want the interactive set-up here, we will manually close and then delete the objects. And hopefully this kills the dashboard properly. If not, restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "del client\n",
    "cluster.close()\n",
    "del cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything in a single cell\n",
    "\n",
    "For the exercise, it'll be easier to have everything in a single cell with context managers. So, here you go. (Note that this assumes z has already been defined.) I'm so nice to you guys. <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LocalCluster(n_workers=1, threads_per_worker=4) as cluster:\n",
    "    with Client(cluster) as client:\n",
    "        z.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
